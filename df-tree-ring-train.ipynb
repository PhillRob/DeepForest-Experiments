{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rasterio._version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# imports\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrasterio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m exists\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\torch\\lib\\site-packages\\rasterio\\__init__.py:28\u001b[0m\n\u001b[0;32m     24\u001b[0m                     os\u001b[39m.\u001b[39madd_dll_directory(p)\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasterio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasterio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m gdal_version, get_geos_version, get_proj_version\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasterio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcrs\u001b[39;00m \u001b[39mimport\u001b[39;00m CRS\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mrasterio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdrivers\u001b[39;00m \u001b[39mimport\u001b[39;00m driver_from_extension, is_blacklisted\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'rasterio._version'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import rasterio\n",
    "import time\n",
    "from os.path import exists\n",
    "from deepforest import main, utilities, get_data, preprocess\n",
    "#type(deepforest.main)\n",
    "from  PIL import Image, ImagePath\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "model = main.deepforest()\n",
    "model.use_release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to load PyTorch C extensions:\n    It appears that PyTorch has loaded the `torch/_C` folder\n    of the PyTorch repository rather than the C extensions which\n    are expected in the `torch._C` namespace. This can occur when\n    using the `install` workflow. e.g.\n        $ python setup.py install && python -c \"import torch\"\n\n    This error can generally be solved using the `develop` workflow\n        $ python setup.py develop && python -c \"import torch\"  # This should succeed\n    or by running Python from a different directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpycuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdriver\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcuda\u001b[39;00m\n\u001b[0;32m      4\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\__init__.py:219\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# The __file__ check only works for Python 3.7 and above.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m7\u001b[39m) \u001b[39mand\u001b[39;00m _C_for_compiled_check\u001b[39m.\u001b[39m\u001b[39m__file__\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(textwrap\u001b[39m.\u001b[39mdedent(\u001b[39m'''\u001b[39m\n\u001b[0;32m    220\u001b[0m \u001b[39m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    221\u001b[0m \u001b[39m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m    222\u001b[0m \u001b[39m                of the PyTorch repository rather than the C extensions which\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39m                are expected in the `torch._C` namespace. This can occur when\u001b[39m\n\u001b[0;32m    224\u001b[0m \u001b[39m                using the `install` workflow. e.g.\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[39m                    $ python setup.py install && python -c \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimport torch\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[39m                This error can generally be solved using the `develop` workflow\u001b[39m\n\u001b[0;32m    228\u001b[0m \u001b[39m                    $ python setup.py develop && python -c \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimport torch\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  # This should succeed\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    230\u001b[0m \u001b[39m            \u001b[39m\u001b[39m'''\u001b[39m)\u001b[39m.\u001b[39mstrip()) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    231\u001b[0m     \u001b[39mraise\u001b[39;00m  \u001b[39m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m(_C):\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to load PyTorch C extensions:\n    It appears that PyTorch has loaded the `torch/_C` folder\n    of the PyTorch repository rather than the C extensions which\n    are expected in the `torch._C` namespace. This can occur when\n    using the `install` workflow. e.g.\n        $ python setup.py install && python -c \"import torch\"\n\n    This error can generally be solved using the `develop` workflow\n        $ python setup.py develop && python -c \"import torch\"  # This should succeed\n    or by running Python from a different directory."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#cuda.init()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49minit()\u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#torch.multiprocessing.set_start_method('spawn',force=True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m## Get Id of default device\u001b[39;00m\n\u001b[0;32m      5\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mcurrent_device()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\cuda\\__init__.py:198\u001b[0m, in \u001b[0;36minit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minit\u001b[39m():\n\u001b[0;32m    189\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Initialize PyTorch's CUDA state.  You may need to call\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39m    this explicitly if you are interacting with PyTorch via\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[39m    its C API, as Python bindings for CUDA functionality will not\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m    Does nothing if the CUDA state is already initialized.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 198\u001b[0m     _lazy_init()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#cuda.init()\n",
    "torch.cuda.init()#\n",
    "#torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"c:\\Users\\Robeck\\anaconda3\\envs\\torch\\python.exe\"\n  * The NumPy version is: \"1.24.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdeepforest\u001b[39;00m \u001b[39mimport\u001b[39;00m main\n\u001b[0;32m      2\u001b[0m m \u001b[39m=\u001b[39m main\u001b[39m.\u001b[39mdeepforest()\n\u001b[0;32m      3\u001b[0m m\u001b[39m.\u001b[39muse_release()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\torch\\lib\\site-packages\\deepforest\\main.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# entry point for deepforest model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\__init__.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m         _missing_dependencies\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_dependency\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m_e\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[39mif\u001b[39;00m _missing_dependencies:\n\u001b[1;32m---> 16\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m     17\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to import required dependencies:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(_missing_dependencies)\n\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"c:\\Users\\Robeck\\anaconda3\\envs\\torch\\python.exe\"\n  * The NumPy version is: \"1.24.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from deepforest import main\n",
    "m = main.deepforest()\n",
    "m.use_release()\n",
    "print(\"Current device is {}\".format(m.device))\n",
    "m.to(\"cuda\")\n",
    "print(\"Current device is {}\".format(m.device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "('R', 'G', 'B')\n",
      "(293506, 132883)\n"
     ]
    }
   ],
   "source": [
    "image_path = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\2_Aerial\\\\GeoTiff\\\\00_QiddiyaMultispectral_3Bands_RGB\\\\QiddiyaMultispectral_3Bands_RGB3.tif\")\n",
    "print(exists(image_path))\n",
    "\n",
    "exImg = Image.open(image_path)\n",
    "print(exImg.getbands())\n",
    "print(exImg.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_shp=r\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path, savedir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training and testing\n",
    "train = annotations.sample(frac = 0.75)\n",
    "test = annotations.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.to_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\\\BoundingBoxes\\\\BoundingBoxes3-train.csv\")\n",
    "test.to_csv(\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_csv=\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3-train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\\\BoundingBoxes\\\\BoundingBoxes3-train.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\preprocess.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.image_path = \"{}_{}.png\".format(image_basename, index)\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\preprocess.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmax = (selected_annotations.xmin - window_xmin) + (\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\preprocess.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmin = (selected_annotations.xmin - window_xmin)\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\preprocess.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymax = (selected_annotations.ymin - window_ymin) + (\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\preprocess.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymin = (selected_annotations.ymin - window_ymin)\n"
     ]
    }
   ],
   "source": [
    "#Write csv to file and crop\n",
    "\n",
    "tmpdir=\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\\\crop\\\\\"\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_2846.png</td>\n",
       "      <td>454</td>\n",
       "      <td>223</td>\n",
       "      <td>500</td>\n",
       "      <td>308</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3198.png</td>\n",
       "      <td>332</td>\n",
       "      <td>407</td>\n",
       "      <td>396</td>\n",
       "      <td>491</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3199.png</td>\n",
       "      <td>332</td>\n",
       "      <td>32</td>\n",
       "      <td>396</td>\n",
       "      <td>116</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3201.png</td>\n",
       "      <td>79</td>\n",
       "      <td>223</td>\n",
       "      <td>125</td>\n",
       "      <td>308</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3557.png</td>\n",
       "      <td>259</td>\n",
       "      <td>376</td>\n",
       "      <td>325</td>\n",
       "      <td>469</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277570.png</td>\n",
       "      <td>207</td>\n",
       "      <td>90</td>\n",
       "      <td>275</td>\n",
       "      <td>125</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277922.png</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>64</td>\n",
       "      <td>481</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277923.png</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277924.png</td>\n",
       "      <td>76</td>\n",
       "      <td>465</td>\n",
       "      <td>144</td>\n",
       "      <td>500</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277925.png</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>125</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13102 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_path  xmin  ymin  xmax  ymax  \\\n",
       "6680    QiddiyaMultispectral_3Bands_RGB3_2846.png   454   223   500   308   \n",
       "4979    QiddiyaMultispectral_3Bands_RGB3_3198.png   332   407   396   491   \n",
       "4979    QiddiyaMultispectral_3Bands_RGB3_3199.png   332    32   396   116   \n",
       "6680    QiddiyaMultispectral_3Bands_RGB3_3201.png    79   223   125   308   \n",
       "5129    QiddiyaMultispectral_3Bands_RGB3_3557.png   259   376   325   469   \n",
       "...                                           ...   ...   ...   ...   ...   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277570.png   207    90   275   125   \n",
       "4802  QiddiyaMultispectral_3Bands_RGB3_277922.png     0   402    64   481   \n",
       "4802  QiddiyaMultispectral_3Bands_RGB3_277923.png     0    27    64   106   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277924.png    76   465   144   500   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277925.png    76    90   144   125   \n",
       "\n",
       "     label  \n",
       "6680  Tree  \n",
       "4979  Tree  \n",
       "4979  Tree  \n",
       "6680  Tree  \n",
       "5129  Tree  \n",
       "...    ...  \n",
       "2194  Tree  \n",
       "4802  Tree  \n",
       "4802  Tree  \n",
       "2194  Tree  \n",
       "2194  Tree  \n",
       "\n",
       "[13102 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Drone-data\\Qiddiya Multispectral\\16_Additional_Data_Output\\crop\\QiddiyaMultispectral_3Bands_RGB3.csv\")\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\data\\deepforest_config.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from DeepForest release https://github.com/weecology/DeepForest/releases/tag/1.0.0 was already downloaded. Loading model from file.\n",
      "Loading pre-built model: https://github.com/weecology/DeepForest/releases/tag/1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus='-1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='-1')` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mnum_worker\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39m# model.config['max_epochs']=10\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49mcreate_trainer()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\main.py:134\u001b[0m, in \u001b[0;36mdeepforest.create_trainer\u001b[1;34m(self, logger, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     enable_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(logger\u001b[39m=\u001b[39mlogger,\n\u001b[0;32m    135\u001b[0m                           max_epochs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    136\u001b[0m                           enable_checkpointing\u001b[39m=\u001b[39menable_checkpointing,\n\u001b[0;32m    137\u001b[0m                           gpus\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mgpus\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    138\u001b[0m                           accelerator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    139\u001b[0m                           fast_dev_run\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mfast_dev_run\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    140\u001b[0m                           callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    141\u001b[0m                           \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:340\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[0;32m    339\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:414\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, inference_mode)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[1;32m--> 414\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[0;32m    415\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[0;32m    416\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[0;32m    417\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[0;32m    418\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[0;32m    419\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[0;32m    420\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m    421\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[0;32m    422\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[0;32m    423\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[0;32m    424\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[0;32m    425\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[0;32m    426\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m    427\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[0;32m    428\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[0;32m    429\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[0;32m    430\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[0;32m    431\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[0;32m    432\u001b[0m )\n\u001b[0;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[0;32m    434\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:208\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_gpu_accelerator_backend()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[0;32m    210\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:528\u001b[0m, in \u001b[0;36mAcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m accelerator_cls\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    523\u001b[0m     available_accelerator \u001b[39m=\u001b[39m [\n\u001b[0;32m    524\u001b[0m         acc_str\n\u001b[0;32m    525\u001b[0m         \u001b[39mfor\u001b[39;00m acc_str \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_types\n\u001b[0;32m    526\u001b[0m         \u001b[39mif\u001b[39;00m AcceleratorRegistry[acc_str][\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mis_available()\n\u001b[0;32m    527\u001b[0m     ]\n\u001b[1;32m--> 528\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m    529\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00maccelerator_cls\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    531\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    535\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[0;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: `CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "model = main.deepforest()\n",
    "model.use_release()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500,patch_overlap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 5000,5000\n",
    "left, upper, right, lower = 500, 2000, width, height\n",
    "cropped_image = Image.crop((left, upper, right, lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.save(\"C:\\\\Users\\\\Robeck\\\\Downloads\\\\AlHair_Clip_GeoTiff-3b.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbImg=get_data(\"C:\\\\Users\\\\Robeck\\\\Downloads\\\\AlHair_Clip_GeoTiff-3b.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=600,patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(image_path)\n",
    "predicted_raster.shape\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "src = rasterio.open(image_path)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# transform rasterio plot to real world coords\n",
    "extent=[src.bounds[0], src.bounds[2], src.bounds[1], src.bounds[3]]\n",
    "ax = rasterio.plot.show(src, extent=extent, ax=ax, cmap='pink')\n",
    "\n",
    "gdf.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('dataframe-300.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ano_shp=\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path,  savedir='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.to_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_csv=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write csv to file and crop\n",
    "tmpdir = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\crop\\\\\")\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6\n",
    "annotations_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\")\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_split\n",
    "# os.path.dirname(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main.deepforest()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "# model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n",
    "model.use_release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model.model.state_dict(),image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = model.predict_image(path=image_path, return_plot = True)\n",
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500,patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rasterio.open(image_path)\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)\n",
    "\n",
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('trained-500-5e.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Image class from PIL module\n",
    " \n",
    "# Opens a image in RGB mode\n",
    "RUH_img = Image.open(r\"\\\\?\\D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\08 GIS-data\\GIS-data-Riyadh\\2022-03-world-view-3\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_I542628_FL01-P244705\\RCRC-4Bands-Mosaic_MOS\\22FEB15073634-S2AM-RCRC-4Bands-Mosaic.TIF\")\n",
    "\n",
    "DQ_img = Image.open(r\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\PNG\\\\DQ_2022_3b.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQ_img.getbbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DQ_img.format, DQ_img.size, DQ_img.mode,DQ_img.getbbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fcc8838d3ce91c74fa0c120fe7aa88709175b787893116cd1c3f23cb2cee5ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
