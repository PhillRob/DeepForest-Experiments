{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import rasterio\n",
    "import time\n",
    "from os.path import exists\n",
    "from deepforest import main, utilities, get_data, preprocess\n",
    "#type(deepforest.main)\n",
    "from  PIL import Image, ImagePath\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "('R', 'G', 'B')\n",
      "(148236, 123881)\n",
      "EPSG:32637\n"
     ]
    }
   ],
   "source": [
    "# get and check Image\n",
    "image_path = (r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\02-satellite\\Makkah-WV2-ST-2023_I602488\\Makkah-WV2-ST-2023-MOS\\23JAN19075627-S2AM-Makkah-WV2-ST-2023.TIF\")\n",
    "# \"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\PNG\\DQ_2022_3b.png\"\n",
    "print(exists(image_path))\n",
    "\n",
    "# annotations = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.csv\")\n",
    "# print(exists(annotations))\n",
    "\n",
    "exImg=Image.open(image_path)\n",
    "print(exImg.getbands())\n",
    "print(exImg.size)\n",
    "src = rasterio.open(image_path)\n",
    "\n",
    "transform = src.transform \n",
    "crs = src.crs\n",
    "print(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get training bonding box and convert to the right format\n",
    "ano_shp=r\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path,  savedir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training and testing\n",
    "train = annotations.sample(frac = 0.75)\n",
    "test = annotations.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.to_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\\\BoundingBoxes\\\\BoundingBoxes3-train.csv\")\n",
    "test.to_csv(\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_csv=\"D:\\\\Dropbox\\P.Robeck\\BPLA Dropbox\\\\07 Temp\\Drone-data\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\BoundingBoxes\\BoundingBoxes3-train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.image_path = \"{}_{}.png\".format(image_basename, index)\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmax = (selected_annotations.xmin - window_xmin) + (\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmin = (selected_annotations.xmin - window_xmin)\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymax = (selected_annotations.ymin - window_ymin) + (\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymin = (selected_annotations.ymin - window_ymin)\n"
     ]
    }
   ],
   "source": [
    "#Write csv to file and crop\n",
    "\n",
    "tmpdir=\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Drone-data\\\\Qiddiya Multispectral\\\\16_Additional_Data_Output\\\\crop\\\\\"\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_2846.png</td>\n",
       "      <td>454</td>\n",
       "      <td>223</td>\n",
       "      <td>500</td>\n",
       "      <td>308</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3198.png</td>\n",
       "      <td>332</td>\n",
       "      <td>407</td>\n",
       "      <td>396</td>\n",
       "      <td>491</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3199.png</td>\n",
       "      <td>332</td>\n",
       "      <td>32</td>\n",
       "      <td>396</td>\n",
       "      <td>116</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3201.png</td>\n",
       "      <td>79</td>\n",
       "      <td>223</td>\n",
       "      <td>125</td>\n",
       "      <td>308</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_3557.png</td>\n",
       "      <td>259</td>\n",
       "      <td>376</td>\n",
       "      <td>325</td>\n",
       "      <td>469</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277570.png</td>\n",
       "      <td>207</td>\n",
       "      <td>90</td>\n",
       "      <td>275</td>\n",
       "      <td>125</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277922.png</td>\n",
       "      <td>0</td>\n",
       "      <td>402</td>\n",
       "      <td>64</td>\n",
       "      <td>481</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277923.png</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277924.png</td>\n",
       "      <td>76</td>\n",
       "      <td>465</td>\n",
       "      <td>144</td>\n",
       "      <td>500</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>QiddiyaMultispectral_3Bands_RGB3_277925.png</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>125</td>\n",
       "      <td>Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13102 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_path  xmin  ymin  xmax  ymax  \\\n",
       "6680    QiddiyaMultispectral_3Bands_RGB3_2846.png   454   223   500   308   \n",
       "4979    QiddiyaMultispectral_3Bands_RGB3_3198.png   332   407   396   491   \n",
       "4979    QiddiyaMultispectral_3Bands_RGB3_3199.png   332    32   396   116   \n",
       "6680    QiddiyaMultispectral_3Bands_RGB3_3201.png    79   223   125   308   \n",
       "5129    QiddiyaMultispectral_3Bands_RGB3_3557.png   259   376   325   469   \n",
       "...                                           ...   ...   ...   ...   ...   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277570.png   207    90   275   125   \n",
       "4802  QiddiyaMultispectral_3Bands_RGB3_277922.png     0   402    64   481   \n",
       "4802  QiddiyaMultispectral_3Bands_RGB3_277923.png     0    27    64   106   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277924.png    76   465   144   500   \n",
       "2194  QiddiyaMultispectral_3Bands_RGB3_277925.png    76    90   144   125   \n",
       "\n",
       "     label  \n",
       "6680  Tree  \n",
       "4979  Tree  \n",
       "4979  Tree  \n",
       "6680  Tree  \n",
       "5129  Tree  \n",
       "...    ...  \n",
       "2194  Tree  \n",
       "4802  Tree  \n",
       "4802  Tree  \n",
       "2194  Tree  \n",
       "2194  Tree  \n",
       "\n",
       "[13102 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Drone-data\\Qiddiya Multispectral\\16_Additional_Data_Output\\crop\\QiddiyaMultispectral_3Bands_RGB3.csv\")\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\data\\deepforest_config.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from DeepForest release https://github.com/weecology/DeepForest/releases/tag/1.0.0 was already downloaded. Loading model from file.\n",
      "Loading pre-built model: https://github.com/weecology/DeepForest/releases/tag/1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus='-1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='-1')` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mnum_worker\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[39m# model.config['max_epochs']=10\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model\u001b[39m.\u001b[39;49mcreate_trainer()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\deepforest\\main.py:134\u001b[0m, in \u001b[0;36mdeepforest.create_trainer\u001b[1;34m(self, logger, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    132\u001b[0m     enable_checkpointing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(logger\u001b[39m=\u001b[39mlogger,\n\u001b[0;32m    135\u001b[0m                           max_epochs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    136\u001b[0m                           enable_checkpointing\u001b[39m=\u001b[39menable_checkpointing,\n\u001b[0;32m    137\u001b[0m                           gpus\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mgpus\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    138\u001b[0m                           accelerator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    139\u001b[0m                           fast_dev_run\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mfast_dev_run\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    140\u001b[0m                           callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    141\u001b[0m                           \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py:340\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    337\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[0;32m    339\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[1;32m--> 340\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:414\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, logger, enable_checkpointing, callbacks, default_root_dir, gradient_clip_val, gradient_clip_algorithm, num_nodes, num_processes, devices, gpus, auto_select_gpus, tpu_cores, ipus, enable_progress_bar, overfit_batches, track_grad_norm, check_val_every_n_epoch, fast_dev_run, accumulate_grad_batches, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, val_check_interval, log_every_n_steps, accelerator, strategy, sync_batchnorm, precision, enable_model_summary, num_sanity_val_steps, resume_from_checkpoint, profiler, benchmark, deterministic, reload_dataloaders_every_n_epochs, auto_lr_find, replace_sampler_ddp, detect_anomaly, auto_scale_batch_size, plugins, amp_backend, amp_level, move_metrics_to_cpu, multiple_trainloader_mode, inference_mode)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m DataConnector(\u001b[39mself\u001b[39m, multiple_trainloader_mode)\n\u001b[1;32m--> 414\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m AcceleratorConnector(\n\u001b[0;32m    415\u001b[0m     num_processes\u001b[39m=\u001b[39;49mnum_processes,\n\u001b[0;32m    416\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[0;32m    417\u001b[0m     tpu_cores\u001b[39m=\u001b[39;49mtpu_cores,\n\u001b[0;32m    418\u001b[0m     ipus\u001b[39m=\u001b[39;49mipus,\n\u001b[0;32m    419\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[0;32m    420\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[0;32m    421\u001b[0m     gpus\u001b[39m=\u001b[39;49mgpus,\n\u001b[0;32m    422\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[0;32m    423\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[0;32m    424\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[0;32m    425\u001b[0m     replace_sampler_ddp\u001b[39m=\u001b[39;49mreplace_sampler_ddp,\n\u001b[0;32m    426\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m    427\u001b[0m     auto_select_gpus\u001b[39m=\u001b[39;49mauto_select_gpus,\n\u001b[0;32m    428\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[0;32m    429\u001b[0m     amp_type\u001b[39m=\u001b[39;49mamp_backend,\n\u001b[0;32m    430\u001b[0m     amp_level\u001b[39m=\u001b[39;49mamp_level,\n\u001b[0;32m    431\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[0;32m    432\u001b[0m )\n\u001b[0;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[0;32m    434\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:208\u001b[0m, in \u001b[0;36mAcceleratorConnector.__init__\u001b[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, amp_type, amp_level, sync_batchnorm, benchmark, replace_sampler_ddp, deterministic, auto_select_gpus, num_processes, tpu_cores, ipus, gpus)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_gpu_accelerator_backend()\n\u001b[1;32m--> 208\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[0;32m    210\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\anaconda3\\envs\\deepforest\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:528\u001b[0m, in \u001b[0;36mAcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m accelerator_cls\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m    523\u001b[0m     available_accelerator \u001b[39m=\u001b[39m [\n\u001b[0;32m    524\u001b[0m         acc_str\n\u001b[0;32m    525\u001b[0m         \u001b[39mfor\u001b[39;00m acc_str \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_types\n\u001b[0;32m    526\u001b[0m         \u001b[39mif\u001b[39;00m AcceleratorRegistry[acc_str][\u001b[39m\"\u001b[39m\u001b[39maccelerator\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mis_available()\n\u001b[0;32m    527\u001b[0m     ]\n\u001b[1;32m--> 528\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[0;32m    529\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00maccelerator_cls\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    530\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    531\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    535\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[0;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gpus\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: `CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "model = main.deepforest()\n",
    "model.use_release()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500,patch_overlap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 5000,5000\n",
    "left, upper, right, lower = 500, 2000, width, height\n",
    "cropped_image = Image.crop((left, upper, right, lower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.save(\"C:\\\\Users\\\\Robeck\\\\Downloads\\\\AlHair_Clip_GeoTiff-3b.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbImg=get_data(\"C:\\\\Users\\\\Robeck\\\\Downloads\\\\AlHair_Clip_GeoTiff-3b.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=600,patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(image_path)\n",
    "predicted_raster.shape\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "src = rasterio.open(image_path)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# transform rasterio plot to real world coords\n",
    "extent=[src.bounds[0], src.bounds[2], src.bounds[1], src.bounds[3]]\n",
    "ax = rasterio.plot.show(src, extent=extent, ax=ax, cmap='pink')\n",
    "\n",
    "gdf.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('dataframe-300.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ano_shp=\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path,  savedir='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.to_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_csv=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write csv to file and crop\n",
    "tmpdir = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\crop\\\\\")\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6\n",
    "annotations_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\")\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_split\n",
    "# os.path.dirname(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main.deepforest()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "# model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n",
    "model.use_release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "# torch.save(model.model.state_dict(),image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = model.predict_image(path=image_path, return_plot = True)\n",
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500,patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rasterio.open(image_path)\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)\n",
    "\n",
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('trained-500-5e.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Image class from PIL module\n",
    " \n",
    "# Opens a image in RGB mode\n",
    "RUH_img = Image.open(r\"\\\\?\\D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\08 GIS-data\\GIS-data-Riyadh\\2022-03-world-view-3\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_I542628_FL01-P244705\\RCRC-4Bands-Mosaic_MOS\\22FEB15073634-S2AM-RCRC-4Bands-Mosaic.TIF\")\n",
    "\n",
    "DQ_img = Image.open(r\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\PNG\\\\DQ_2022_3b.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\df-tree-ring-train.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/df-tree-ring-train.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQ_img.getbbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DQ_img.format, DQ_img.size, DQ_img.mode,DQ_img.getbbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f12eafbfb4f344efca36c41f45dc872892b3fee554b97ee162efb4a5a84b036b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
