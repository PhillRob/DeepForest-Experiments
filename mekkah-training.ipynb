{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# imports\n",
    "import rasterio\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "# import gdal \n",
    "from osgeo import osr, gdal\n",
    "from PIL import Image\n",
    "from PIL.TiffTags import TAGS\n",
    "from os.path import *\n",
    "import json\n",
    "from deepforest import main, utilities, get_data, preprocess\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycuda in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (2022.2.2)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -dal (c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: appdirs>=1.4.0 in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from pycuda) (1.4.4)\n",
      "Requirement already satisfied: pytools>=2011.2 in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from pycuda) (2022.1.14)\n",
      "Requirement already satisfied: mako in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from pycuda) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from pytools>=2011.2->pycuda) (4.4.0)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from pytools>=2011.2->pycuda) (2.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\robeck\\downloads\\df\\.venv\\lib\\site-packages (from mako->pycuda) (2.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycuda\n",
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "(512, 512)\n",
      "EPSG:32637\n",
      "(0.46, 0.46)\n"
     ]
    }
   ],
   "source": [
    "src_img =r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\02-satellite\\Makkah-WV2-ST-2023_I602488\\Makkah-WV2-ST-2023-MOS\\23JAN19075627-S2AM-Makkah-WV2-ST-2023-tiled.TIF\"\n",
    "dst_img= r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\23JAN19075627-S2AM-Makkah-WV2-ST-2023.TIF\"\n",
    "\n",
    "# check if the files exist input file\n",
    "print(exists(src_img))\n",
    "print(exists(dst_img))\n",
    "# img = Image.open(src_img)\n",
    "# print(img.getbands())\n",
    "\n",
    "with rasterio.open(src_img) as src:\n",
    "    for ji, window in src.block_windows(1):\n",
    "        r = src.read(1, window=window)\n",
    "        print(r.shape)\n",
    "        break\n",
    "\n",
    "# rasterio\n",
    "src = rasterio.open(src_img)\n",
    "transform = src.transform \n",
    "crs = src.crs\n",
    "\n",
    "print(crs)\n",
    "print(src.res)\n",
    "# print(img.getbands())\n",
    "# print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_BAG.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_FITS.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_GMT.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF4Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_HDF5Image.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_KEA.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n",
      "Can't load requested DLL: C:\\Program Files\\GDAL\\gdalplugins\\gdal_netCDF.dll\n",
      "127: The specified procedure could not be found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get training bonding box and convert to the right format\n",
    "ano_shp = r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\mekka-training-tree.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, src_img,  savedir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training and testing\n",
    "train = annotations.sample(frac = 0.75)\n",
    "test = annotations.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\bbox\\mekka-training-tree-train.csv\"\n",
    "test_path=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\bbox\\mekka-training-tree-test.csv\"\n",
    "\n",
    "train.to_csv(train_path)\n",
    "test.to_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.image_path = \"{}_{}.png\".format(image_basename, index)\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmax = (selected_annotations.xmin - window_xmin) + (\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.xmin = (selected_annotations.xmin - window_xmin)\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymax = (selected_annotations.ymin - window_ymin) + (\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:115: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_annotations.ymin = (selected_annotations.ymin - window_ymin)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <i2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\PIL\\Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     mode, rawmode \u001b[39m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[0;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 3), '<i2')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\mekkah-training.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tmpdir \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDropbox\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mP.Robeck\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBPLA Dropbox\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m03 Planning\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m1297-Makkah-Environmental-Sustainability-Strategy\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m02-Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m03-poc\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mcrop\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m annotations_file \u001b[39m=\u001b[39m preprocess\u001b[39m.\u001b[39;49msplit_raster(path_to_raster\u001b[39m=\u001b[39;49msrc_img,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                            annotations_file\u001b[39m=\u001b[39;49mtrain_path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                            base_dir\u001b[39m=\u001b[39;49mtmpdir,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                            patch_size\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Robeck/Downloads/df/mekkah-training.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                            patch_overlap\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:252\u001b[0m, in \u001b[0;36msplit_raster\u001b[1;34m(annotations_file, path_to_raster, numpy_image, base_dir, patch_size, patch_overlap, allow_empty, image_name)\u001b[0m\n\u001b[0;32m    249\u001b[0m         annotations_files\u001b[39m.\u001b[39mappend(crop_annotations)\n\u001b[0;32m    251\u001b[0m         \u001b[39m# save image crop\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m         save_crop(base_dir, image_name, index, crop)\n\u001b[0;32m    253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(annotations_files) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    254\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput file has no overlapping annotations and allow_empty is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    256\u001b[0m             allow_empty))\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\preprocess.py:135\u001b[0m, in \u001b[0;36msave_crop\u001b[1;34m(base_dir, image_name, index, crop)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(base_dir):\n\u001b[0;32m    133\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(base_dir)\n\u001b[1;32m--> 135\u001b[0m im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(crop)\n\u001b[0;32m    136\u001b[0m image_basename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplitext(image_name)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    137\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(base_dir, image_basename, index)\n",
      "File \u001b[1;32mc:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\PIL\\Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3082\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot handle this data type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m typekey\n\u001b[1;32m-> 3083\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     rawmode \u001b[39m=\u001b[39m mode\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <i2"
     ]
    }
   ],
   "source": [
    "#Write csv to file and crop\n",
    "\n",
    "tmpdir = r'D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\bbox\\crop'\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=src_img,\n",
    "                                           annotations_file=train_path,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\1297-Makkah-Environmental-Sustainability-Strategy\\02-Data\\03-poc\\bbox\\crop\\23JAN19075627-S2AM-Makkah-WV2-ST-2023.csv\")\n",
    "exists(ano_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\deepforest\\data\\deepforest_config.yml\n",
      "Model from DeepForest release https://github.com/weecology/DeepForest/releases/tag/1.0.0 was already downloaded. Loading model from file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:467: LightningDeprecationWarning: Setting `Trainer(gpus='-1')` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices='-1')` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-built model: https://github.com/weecology/DeepForest/releases/tag/1.0.0\n"
     ]
    }
   ],
   "source": [
    "model = main.deepforest()\n",
    "model.use_release()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | RetinaNet | 32.1 M\n",
      "------------------------------------\n",
      "31.9 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "32.1 M    Total params\n",
      "128.592   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:366: UserWarning: One of given dataloaders is None and it will be skipped.\n",
      "  rank_zero_warn(\"One of given dataloaders is None and it will be skipped.\")\n",
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 472/472 [02:25<00:00,  3.25it/s, loss=1.35] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 472/472 [02:25<00:00,  3.25it/s, loss=1.35]\n",
      "--- Training on CPU: 681.41 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(),'model-500.pth', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1872/130745 [03:32<4:04:34,  8.78it/s]"
     ]
    }
   ],
   "source": [
    "predicted_raster = model.predict_tile(src_img, return_plot = False, patch_size=500,patch_overlap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
