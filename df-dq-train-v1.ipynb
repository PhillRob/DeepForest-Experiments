{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\Downloads\\df\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os, rasterio\n",
    "import time\n",
    "from deepforest import main, utilities, get_data, preprocess \n",
    "from os.path import exists\n",
    "from  PIL import Image, ImagePath\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and check Image\n",
    "image_path=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\img\\DQ_2022_3b.tif\"\n",
    "# \"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\PNG\\DQ_2022_3b.png\"\n",
    "print(exists(image_path))\n",
    "\n",
    "# annotations = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.csv\")\n",
    "# print(exists(annotations))\n",
    "\n",
    "exImg=Image.open(image_path)\n",
    "print(exImg.getbands())\n",
    "print(exImg.size)\n",
    "src = rasterio.open(image_path)\n",
    "\n",
    "transform = src.transform \n",
    "crs = src.crs\n",
    "print(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training bonding box and convert to the right format\n",
    "ano_shp=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\DQ-Vegetation-Analysis-1180\\03_Data\\model-training\\20230121-Five-classes-data-v1\\5classes-treesdata-start-December2022-1.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path,  savedir='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first column\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ano_csv=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\03 Planning\\DQ-Vegetation-Analysis-1180\\03_Data\\model-training\\20230121-Five-classes-data-v1\\1class-treesdata-start-December2022.csv\"\n",
    "annotations.to_csv(ano_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(pd.read_csv(ano_csv,index_col=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write csv to file and crop to patches\n",
    "tmpdir = (r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\")\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file\n",
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file.to_csv(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\",index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_split=(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\")\n",
    "print(pd.DataFrame(pd.read_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\crop\\\\DQ_2022_3b.csv\")))\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ano_split\n",
    "# os.path.dirname(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main.deepforest()\n",
    "model.use_release()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to the image\n",
    "# boxes = model.predict_image(path=image_path, return_plot = True)\n",
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500, patch_overlap=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to projected cooridinate system\n",
    "r = rasterio.open(image_path)\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)\n",
    "\n",
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('DQ-trained-500-5e-5c.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(ano_split, os.path.dirname(ano_split), iou_threshold = 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[\"box_recall\"])\n",
    "print(results[\"box_precision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"results\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f12eafbfb4f344efca36c41f45dc872892b3fee554b97ee162efb4a5a84b036b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
